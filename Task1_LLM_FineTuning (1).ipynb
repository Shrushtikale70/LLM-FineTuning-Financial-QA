{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t4C0pbJ6IGG"
      },
      "source": [
        "# LLM Fine-Tuning for Financial Question Answering\n",
        "Baseline vs LoRA Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvPKvVB86IGH"
      },
      "source": [
        "!pip install -q transformers datasets peft accelerate evaluate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmbQVA0l6IGI"
      },
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import evaluate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmg_PkrX6IGI"
      },
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK7I6a4u6IGI"
      },
      "source": [
        "dataset = load_dataset(\"ExplodingGradients/fiqa\", \"main\")\n",
        "train_dataset = dataset['train']\n",
        "val_dataset = dataset['validation']\n",
        "test_dataset = dataset['test']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziH80lhi6IGI"
      },
      "source": [
        "## Load Base Model (DistilGPT2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5_PuBJr6IGI"
      },
      "source": [
        "model_name = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ay-HEX6IGI"
      },
      "source": [
        "## Baseline Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbi_eb8O6IGI"
      },
      "source": [
        "def generate_answer(question):\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model.generate(**inputs, max_length=100)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN10vHcy6IGI"
      },
      "source": [
        "## Apply LoRA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0aW7xH96IGJ"
      },
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"c_attn\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-A9pavB6IGJ"
      },
      "source": [
        "## Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZS2uLY86IGJ"
      },
      "source": [
        "def tokenize_function(example):\n",
        "    text = example['question'] + \" \" + example['ground_truths'][0]\n",
        "    return tokenizer(text, truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "small_train = train_dataset.select(range(1000)).map(tokenize_function)\n",
        "small_val = val_dataset.select(range(200)).map(tokenize_function)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_val\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJLe-bR26IGJ"
      },
      "source": [
        "## Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaMoFTt86IGJ"
      },
      "source": [
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwlqeczT6IGJ"
      },
      "source": [
        "## Final Comparison\n",
        "Baseline F1: 0.1189\n",
        "LoRA Fine-Tuned F1: 0.0488\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}